{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6368c8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\.conda\\envs\\tensorrt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM,AutoTokenizer,GPTQConfig\n",
    "import torch\n",
    "pretrained_model_dir = \"bloom-560m\"\n",
    "quantized_model_dir = \"bloom-560m_GPTQ\"\n",
    "\n",
    "quantization_config=GPTQConfig(\n",
    "    bits=4,\n",
    "    group_size=128,\n",
    "    dataset=\"c4\",\n",
    "    desc_act=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f241034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "C:\\Users\\l\\.conda\\envs\\tensorrt\\lib\\site-packages\\datasets\\table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Quantizing transformer.h blocks :   0%|                                                         | 0/24 [00:00<?, ?it/s]\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:04<00:14,  4.68s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:07<00:06,  3.37s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:09<00:02,  2.95s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:14<00:00,  3.57s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :   4%|██                                               | 1/24 [00:16<06:10, 16.12s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.49s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:05<00:05,  2.51s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.50s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:12<00:00,  3.52s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :   8%|████                                             | 2/24 [00:30<05:35, 15.26s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.48s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.29s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  12%|██████▏                                          | 3/24 [00:44<05:08, 14.67s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.26s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  17%|████████▏                                        | 4/24 [00:58<04:46, 14.34s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.26s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  21%|██████████▏                                      | 5/24 [01:12<04:29, 14.16s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.25s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  25%|████████████▎                                    | 6/24 [01:26<04:13, 14.06s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.26s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  29%|██████████████▎                                  | 7/24 [01:40<03:57, 13.99s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.26s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  33%|████████████████▎                                | 8/24 [01:54<03:43, 13.95s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.48s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:05,  2.50s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.50s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:12<00:00,  3.33s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  38%|██████████████████▍                              | 9/24 [02:08<03:30, 14.01s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.28s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  42%|████████████████████                            | 10/24 [02:22<03:15, 14.00s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.28s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  46%|██████████████████████                          | 11/24 [02:36<03:01, 13.98s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.28s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  50%|████████████████████████                        | 12/24 [02:49<02:47, 13.96s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.28s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  54%|██████████████████████████                      | 13/24 [03:03<02:33, 13.96s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.29s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  58%|████████████████████████████                    | 14/24 [03:17<02:19, 13.96s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.27s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  62%|██████████████████████████████                  | 15/24 [03:31<02:05, 13.94s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.29s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  67%|████████████████████████████████                | 16/24 [03:45<01:51, 13.95s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.27s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  71%|██████████████████████████████████              | 17/24 [03:59<01:37, 13.93s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.28s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  75%|████████████████████████████████████            | 18/24 [04:13<01:23, 13.93s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.28s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  79%|██████████████████████████████████████          | 19/24 [04:27<01:09, 13.94s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.41s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.46s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.32s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  83%|████████████████████████████████████████        | 20/24 [04:41<00:55, 13.96s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.27s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  88%|██████████████████████████████████████████      | 21/24 [04:55<00:41, 13.95s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.48s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.46s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.47s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.28s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  92%|████████████████████████████████████████████    | 22/24 [05:09<00:27, 13.95s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.43s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.26s/it]\u001b[A\n",
      "Quantizing transformer.h blocks :  96%|██████████████████████████████████████████████  | 23/24 [05:23<00:13, 13.91s/it]\u001b[A\n",
      "Quantizing layers inside the block:   0%|                                                        | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      "Quantizing layers inside the block:  25%|████████████                                    | 1/4 [00:02<00:07,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  50%|████████████████████████                        | 2/4 [00:04<00:04,  2.44s/it]\u001b[A\n",
      "Quantizing layers inside the block:  75%|████████████████████████████████████            | 3/4 [00:07<00:02,  2.45s/it]\u001b[A\n",
      "Quantizing layers inside the block: 100%|████████████████████████████████████████████████| 4/4 [00:11<00:00,  3.27s/it]\u001b[A\n",
      "Quantizing transformer.h blocks : 100%|████████████████████████████████████████████████| 24/24 [05:37<00:00, 14.05s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "tokenizers=AutoTokenizer.from_pretrained(pretrained_model_dir)\n",
    "quant_model=AutoModelForCausalLM.from_pretrained(pretrained_model_dir,quantization_config=quantization_config,device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d6d7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=AutoTokenizer.from_pretrained(pretrained_model_dir)\n",
    "text=\"Hello my name is \"\n",
    "inputs=tokenizer(text,return_tensors='pt').to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab17bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l\\.conda\\envs\\tensorrt\\lib\\site-packages\\transformers\\generation\\utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is 赵志强，我是一名大学生，我是一名大学生，我是一名大学生\n"
     ]
    }
   ],
   "source": [
    "out=quant_model.generate(**inputs)\n",
    "print(tokenizer.decode(out[0],skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9acd2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_model.save_pretrained(quantized_model_dir, use_safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4883814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorrt",
   "language": "python",
   "name": "tensorrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
